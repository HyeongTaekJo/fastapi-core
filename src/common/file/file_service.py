# âœ… FileService ë¦¬íŒ©í† ë§ + íŒŒì¼ êµì²´ (ê¸°ì¡´ row ìœ ì§€í•˜ë©° path ìˆ˜ì •)

from typing import Literal, Optional

from fastapi import HTTPException
from common.const.path_consts import TEMP_FOLDER_PATH, TEMP_BACKUP_PATH
from common.file.enums.owner_type_enum import OWNER_TYPE_MAPPING
from common.file.file_utils import (
    get_file_type_by_ext,
    backup_files,
    restore_backups,
    delete_backups,
    move_temp_file_to_target,
    _extract_file_id_from_path
)
from common.file.repository import FileRepository
import os
import logging

logger = logging.getLogger(__name__)

class FileService:
    def __init__(self, target_folder_path: str):
        self.repo = FileRepository()
        self.target_folder_path = target_folder_path

    async def save_files(self, owner_type: str, owner_id: int, temp_filenames: list[str]):
        for index, filename in enumerate(temp_filenames):
            await self.move_from_temp_and_link(
                temp_filename=filename,
                owner_type=owner_type,
                owner_id=owner_id,
                is_main=(index == 0),
                order=index
            )

    async def update_files(self, owner_type: str, owner_id: int, file_payload: list[object]):
        await self.prepare_for_save_or_update(owner_type, owner_id)

        existing_ids = {f.id for f in self._old_files}  # ðŸ”’ ì‹¤ì œ ì—°ê²°ëœ íŒŒì¼ IDë§Œ ì¶”ì¶œ
        logger.debug(f"ðŸ“‚ ê¸°ì¡´ ì—°ê²°ëœ íŒŒì¼ IDë“¤: {existing_ids}")
        received_ids = set()

        try:
            for item in file_payload:
                order = item.order

                # âœ… ê¸°ì¡´ íŒŒì¼ì¸ë° ìƒˆ íŒŒì¼ë¡œ êµì²´
                if item.id and item.temp_name:
                    if item.id in existing_ids:
                        logger.debug(f"âœ… êµì²´ ì²˜ë¦¬ ì¤‘: {item.id}")
                        received_ids.add(item.id)
                        await self.update_existing_file_with_new_temp(
                            file_id=item.id,
                            temp_name=item.temp_name,
                            owner_type=owner_type,
                            owner_id=owner_id,
                            order=order
                        )
                    else:
                        logger.warning(f"âš ï¸ ë¬´ì‹œë¨: item.id={item.id}ëŠ” ì—°ê²°ëœ íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤.")
                        logger.warning(f"âŒ êµì²´ ì‹¤íŒ¨ â†’ item.id={item.id} ëŠ” ê¸°ì¡´ì— ì—†ëŠ” íŒŒì¼ë¡œ íŒë‹¨ë¨")


                # âœ… ê¸°ì¡´ íŒŒì¼ â†’ ìˆœì„œë§Œ ë³€ê²½
                elif item.id:
                    if item.id in existing_ids:
                        logger.debug(f"âœ… ìˆœì„œë§Œ ë³€ê²½: {item.id}")
                        received_ids.add(item.id)
                        await self.repo.update_file_order(item.id, order)
                    else:
                        logger.warning(f"âš ï¸ ë¬´ì‹œë¨: item.id={item.id}ëŠ” ì—°ê²°ëœ íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤.")
                        logger.warning(f"âŒ ìˆœì„œ ë³€ê²½ ì‹¤íŒ¨ â†’ item.id={item.id} ëŠ” ê¸°ì¡´ì— ì—†ëŠ” íŒŒì¼ë¡œ íŒë‹¨ë¨")

                # âœ… ìƒˆ íŒŒì¼ ì¶”ê°€
                elif item.temp_name:
                    await self.move_from_temp_and_link(
                        temp_filename=item.temp_name,
                        owner_type=owner_type,
                        owner_id=owner_id,
                        is_main=(order == 0),
                        order=order
                    )

            to_delete_ids = self._old_file_ids - received_ids
            logger.debug(f"ðŸ§¹ ì‚­ì œ ëŒ€ìƒ file ids: {to_delete_ids}")

            if to_delete_ids:
                # ì‚­ì œí•  íŒŒì¼ë“¤ì˜ ë°±ì—…ì„ ì œì™¸í•˜ê³  ë³µì›
                non_deleted_backups = [
                    (original, backup)
                    for original, backup in self._backups
                    if _extract_file_id_from_path(original) not in to_delete_ids
                ]
                
                # ì‚­ì œë˜ì§€ ì•Šì€ íŒŒì¼ë“¤ë§Œ ë³µì›
                restore_backups(non_deleted_backups)
                
                # ì‚­ì œ ëŒ€ìƒ íŒŒì¼ë“¤ì˜ ë°±ì—…ì€ ì‚­ì œ
                await delete_backups(self._backups, to_delete_ids)
                
                # DBì—ì„œ íŒŒì¼ ì‚­ì œ
                await self.repo.delete_files_by_ids(to_delete_ids)
                
                # ì‚­ì œëœ íŒŒì¼ë“¤ì˜ ì‹¤ì œ íŒŒì¼ë„ ì‚­ì œ
                for original, _ in self._backups:
                    if _extract_file_id_from_path(original) in to_delete_ids:
                        try:
                            if os.path.exists(original):
                                os.remove(original)
                                logger.info(f"ðŸ—‘ï¸ íŒŒì¼ ì‚­ì œ ì™„ë£Œ: {original}")
                        except Exception as e:
                            logger.warning(f"âš ï¸ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {original} - {e}")

            else:
                logger.debug("ðŸŸ¢ ì‚­ì œ ëŒ€ìƒ ì—†ìŒ â†’ ë°±ì—…ëœ ê¸°ì¡´ íŒŒì¼ ë³µì› ì¤‘...")
                restore_backups(self._backups)

        except Exception as e:
            await self.rollback()
            raise e


    async def update_existing_file_with_new_temp(self, file_id: int, temp_name: str, owner_type: str, owner_id: int, order: int):
        file = await self.repo.get_file_by_id(file_id)
        if not file:
            raise HTTPException(status_code=404, detail="íŒŒì¼ì´ ì¡´ìž¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

        # âœ… ê¸°ì¡´ íŒŒì¼ ê²½ë¡œ
        old_full_path = os.path.join(self.target_folder_path, file.path)

        # ì‹ ê·œ ê²½ë¡œ ì„¤ì •
        temp_path = os.path.join(TEMP_FOLDER_PATH, temp_name)
        target_rel_path = os.path.join(owner_type, temp_name)
        target_path = os.path.join(self.target_folder_path, target_rel_path)

        if not os.path.exists(temp_path):
            raise FileNotFoundError("ìž„ì‹œ íŒŒì¼ì´ ì¡´ìž¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

        # âœ… temp â†’ targetìœ¼ë¡œ ë³µì‚¬
        move_temp_file_to_target(temp_path, target_path)
        self.record_moved_file(temp_path, target_path)

        # âœ… ê¸°ì¡´ íŒŒì¼ ì‚­ì œ
        if os.path.exists(old_full_path):
            try:
                os.remove(old_full_path)
                logger.info(f"ðŸ—‘ï¸ ê¸°ì¡´ íŒŒì¼ ì‚­ì œ ì™„ë£Œ: {old_full_path}")
            except Exception as e:
                logger.warning(f"âš ï¸ ê¸°ì¡´ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {old_full_path} - {e}")

        # DB ì—…ë°ì´íŠ¸
        file.path = target_rel_path
        file.original_name = temp_name
        file.size = os.path.getsize(target_path)
        file.order = order
        file.type = get_file_type_by_ext(temp_name)

        await self.repo.session.flush()


    async def move_from_temp_and_link(
        self,
        temp_filename: str,
        owner_type: str,
        owner_id: int,
        description: Optional[str] = None,
        is_main: bool = False,
        order: int = 0
    ):
        subfolder = owner_type
        target_rel_path = os.path.join(subfolder, temp_filename)
        temp_path = os.path.join(TEMP_FOLDER_PATH, temp_filename)
        target_path = os.path.join(self.target_folder_path, target_rel_path)

        try:
            if not os.path.exists(temp_path):
                raise FileNotFoundError("ìž„ì‹œ íŒŒì¼ì´ ì¡´ìž¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

            move_temp_file_to_target(temp_path, target_path)
            self.record_moved_file(temp_path, target_path)

            file_type = get_file_type_by_ext(temp_filename)
            size = os.path.getsize(target_path)
            mapping_field = OWNER_TYPE_MAPPING.get(owner_type)

            await self.repo.create_file_record(
                path=target_rel_path,
                original_name=temp_filename,
                size=size,
                type=file_type,
                is_main=is_main,
                description=description,
                owner_type=owner_type,
                owner_id=owner_id,
                order=order,
                **{mapping_field: owner_id}
            )

        except Exception as e:
            if (temp_path, target_path) in getattr(self, "_moved_files", []):
                move_temp_file_to_target(target_path, temp_path)
            raise HTTPException(status_code=500, detail={
                "error": "FILE_SAVE_FAILED",
                "message": "íŒŒì¼ ì €ìž¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ. ë¡¤ë°±ë˜ì—ˆìŠµë‹ˆë‹¤.",
                "reason": str(e),
            })

    async def prepare_for_save_or_update(self, owner_type: str, owner_id: int):
        existing_files = await self.repo.get_files_by_owner(owner_type, owner_id)
        self._backups = backup_files([f.path for f in existing_files], self.target_folder_path, TEMP_BACKUP_PATH)
        self._old_files = existing_files
        self._old_file_ids = {f.id for f in existing_files}

        logger.debug(f"ðŸ“¦ old_files: {[f.id for f in existing_files]}")

    async def rollback(self):
        if hasattr(self, "_moved_files"):
            for temp_path, target_path in reversed(self._moved_files):
                if os.path.exists(target_path):
                    move_temp_file_to_target(target_path, temp_path)
        if hasattr(self, "_backups"):
            restore_backups(self._backups)

    def record_moved_file(self, src: str, dest: str):
        if not hasattr(self, "_moved_files"):
            self._moved_files = []
        self._moved_files.append((src, dest))


    async def collect_file_paths(self, owner_type: str, owner_id: int) -> list[str]:
        files = await self.get_files_by_owner(owner_type, owner_id)
        return [os.path.join(self.target_folder_path, f.path) for f in files]
    
    async def get_files_by_owner(self, owner_type: str, owner_id: int):
        return await self.repo.get_files_by_owner(owner_type, owner_id)
