import os
from shutil import move
from os.path import join, exists, dirname
from pathlib import Path
import logging
import re
from common.file.enums.file_model_type_enum import FileModelType
from sqlalchemy.ext.asyncio import AsyncSession
from database.dependencies import get_db


logger = logging.getLogger(__name__)

#  1. í™•ì¥ì ê¸°ì¤€ íŒŒì¼ íƒ€ì… ì¶”ì •
ALLOWED_FILE_TYPES = {
    FileModelType.IMAGE: {".jpg", ".jpeg", ".png"},
    FileModelType.PDF: {".pdf"},
    FileModelType.EXCEL: {".xls", ".xlsx"},
    FileModelType.PPT: {".ppt", ".pptx"},
    FileModelType.WORD: {".doc", ".docx"},
    FileModelType.HWP: {".hwp"},
    FileModelType.OTHER: set(),
}

def get_file_type_by_ext(filename: str) -> FileModelType:
    ext = Path(filename).suffix.lower()
    for file_type, extensions in ALLOWED_FILE_TYPES.items():
        if ext in extensions:
            return file_type
    return FileModelType.OTHER

#  2. ì—…ë¡œë“œ ê°€ëŠ¥í•œ íŒŒì¼ ê²€ì¦
MAX_UPLOAD_FILE_SIZE_MB = 10

def validate_file(file) -> None:
    file_type = get_file_type_by_ext(file.filename)
    if file_type == FileModelType.OTHER:
        raise ValueError("ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤.")

    file.file.seek(0, os.SEEK_END)
    size = file.file.tell()
    file.file.seek(0)

    if size > MAX_UPLOAD_FILE_SIZE_MB * 1024 * 1024:
        raise ValueError("íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤.")

#  3. íŒŒì¼ ë°±ì—…: ì›ë³¸ â†’ ë°±ì—… ë””ë ‰í† ë¦¬
def backup_files(paths: list[str], src_root: str, backup_root: str) -> list[tuple[str, str]]:
    backups = []
    for rel_path in paths:
        original = join(src_root, rel_path)
        backup = join(backup_root, rel_path)
        if exists(original):
            os.makedirs(dirname(backup), exist_ok=True)
            move(original, backup)
            backups.append((original, backup))
            logger.info(f"ğŸ”„ ë°±ì—…: {original} â†’ {backup}")
    return backups

#  4. ë³µì›: ë°±ì—… â†’ ì›ë˜ ìœ„ì¹˜
def restore_backups(backups: list[tuple[str, str]]):
    for original, backup in backups:
        if exists(backup):
            try:
                if exists(original):
                    os.remove(original)  #  move ì „ì— ì‚­ì œ
                    logger.debug(f"ê¸°ì¡´ íŒŒì¼ ì‚­ì œë¨: {original}")
                move(backup, original)
                logger.warning(f" ë³µì›: {backup} â†’ {original}")
            except Exception as e:
                logger.warning(f" ë³µì› ì‹¤íŒ¨: {backup} â†’ {original} - {e}")

async def _extract_file_id_from_path(
    path: str, 
    db: AsyncSession
) -> int:
    # íŒŒì¼ ê²½ë¡œì—ì„œ UUID ë¶€ë¶„ì„ ì¶”ì¶œ
    import re
    match = re.search(r"([a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12})", path.replace("\\", "/"))
    if match:
        # UUIDë¥¼ ê¸°ë°˜ìœ¼ë¡œ DBì—ì„œ íŒŒì¼ IDë¥¼ ì¡°íšŒ
        from common.file.repository import FileRepository
        repo = FileRepository(db)
        file = await repo.get_file_by_uuid(match.group(1))
        return file.id if file else -1
    return -1

#  5. ë°±ì—… ì‚­ì œ
async def delete_backups(
    backups: list[tuple[str, str]], 
    delete_ids: set[int], 
    db: AsyncSession
):
    for original, backup in backups:
        file_id = await _extract_file_id_from_path(original, db)
        if file_id in delete_ids:
            try:
                if exists(backup):
                    os.remove(backup)
                    logger.info(f" ë°±ì—… ì‚­ì œë¨: {backup}")
                if exists(original):
                    os.remove(original)
                    logger.info(f" ì›ë³¸ íŒŒì¼ ì‚­ì œë¨: {original}")
            except Exception as e:
                logger.warning(f" íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {original} - {e}")

#  6. temp â†’ ìµœì¢… ë””ë ‰í† ë¦¬ ì´ë™
def move_temp_file_to_target(temp_path: str, target_path: str):
    os.makedirs(dirname(target_path), exist_ok=True)
    move(temp_path, target_path)
    logger.info(f" ì´ë™ ì™„ë£Œ: {temp_path} â†’ {target_path}")
